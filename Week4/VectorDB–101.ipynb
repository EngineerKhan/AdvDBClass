{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "So far, we have worked primarily with relational databases. We have also explored MongoDB and APIs. These systems excel at filtering and querying structured data based on explicit attributes, such as filtering by a specific field value. However, they struggle when it comes to understanding the semantic meaning behind data — for example, finding items that are similar in meaning rather than exact matches.\n",
    "\n",
    "Today, we will expand our toolkit with something similar yet quite distinct — vector databases.\n",
    "\n",
    "## Background\n",
    "\n",
    "Relational databases, MongoDB, and similar systems are excellent at filtering data by specific attributes or exact matches, which makes them well-suited for structured queries. For example, if we want to find books with a particular word in the title, we can easily do so with MongoDB:\n",
    "\n",
    "```json\n",
    "{\"original_title\": {\"$regex\": \"world\", \"$options\": \"i\"}}\n",
    "```\n",
    "\n",
    "However, these databases are limited when we want to perform semantic search — that is, searching based on the meaning or similarity of content rather than exact keywords. For instance, finding titles that are similar in meaning or recommending books with related themes is challenging with traditional databases.\n",
    "\n",
    "Vector databases address this problem by representing data as vectors in a high-dimensional space. They enable semantic search by performing nearest neighbor searches to find items that are most similar in meaning.\n",
    "\n",
    "> If terms like \"vector space\" sound intimidating, don’t worry — the concept is quite intuitive, as we will see.\n",
    "\n",
    "## Embeddings\n",
    "\n",
    "If you have some basic understanding of machine learning, you know that algorithms like SVMs or neural networks require numerical input. For images, this might be pixel values. For text, however, we need to convert words or sentences into numerical representations that capture their meaning.\n",
    "\n",
    "This is where embeddings come in. Embeddings are numerical vectors that represent text in a way that preserves semantic relationships. A good embedding algorithm ensures that texts with similar meanings have similar vector representations.\n",
    "\n",
    "> Embeddings are not limited to text — they can be applied to images, audio, and other data types as well.\n",
    "\n",
    "For example, consider these embeddings:\n",
    "\n",
    "- `\"king\"` → [0.12, -0.43, ...]\n",
    "- `\"queen\"` → [0.10, -0.40, ...]\n",
    "- `\"apple\"` → [0.87, 0.11, ...]\n",
    "\n",
    "Notice that the vectors for `\"king\"` and `\"queen\"` are close together, while `\"king\"` and `\"apple\"` are far apart, reflecting their semantic similarity.\n",
    "\n",
    "### Calculating Embeddings\n",
    "\n",
    "There are many models available for generating embeddings, broadly classified into:\n",
    "\n",
    "- Classical NLP models\n",
    "- Deep learning models\n",
    "- Transformers\n",
    "\n",
    "Transformers are currently the most popular due to their efficiency, accuracy, and ease of use, thanks to numerous libraries.\n",
    "\n",
    "Popular providers offering transformer-based embedding models include:\n",
    "\n",
    "- HuggingFace\n",
    "- OpenAI\n",
    "- AWS Bedrock\n",
    "\n",
    "#### HuggingFace\n",
    "\n",
    "In 2017, Google Research published a landmark paper titled [Attention Is All You Need](https://arxiv.org/abs/1706.03762), introducing the Transformer architecture. This architecture revolutionized NLP by effectively handling long sequences of text.\n",
    "\n",
    "Following that, models like GPT (2018), BERT (2018), and GPT-2 (2019) pushed the boundaries of what Transformers could achieve. OpenAI's GPT-3 (2020) further advanced the field by generating highly natural text (and won the best paper award at NeurIPS 2020).\n",
    "\n",
    "Since then, Transformers have become the _de facto_ standard for NLP tasks. HuggingFace, launched in 2021, is a great example of a company arriving at the perfect time with a strong team. It provides a rich ecosystem of pre-trained models and tools through its Python `transformers` library.\n",
    "\n",
    "To install the library, run:"
   ],
   "id": "f8e625520728ae55"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-09-23T04:32:11.144072Z",
     "start_time": "2025-09-23T04:32:09.697400Z"
    }
   },
   "source": "!pip install transformers sentence-transformers",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /opt/anaconda3/envs/AdvDB/lib/python3.13/site-packages (4.56.2)\r\n",
      "Requirement already satisfied: sentence-transformers in /opt/anaconda3/envs/AdvDB/lib/python3.13/site-packages (5.1.0)\r\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/envs/AdvDB/lib/python3.13/site-packages (from transformers) (3.19.1)\r\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /opt/anaconda3/envs/AdvDB/lib/python3.13/site-packages (from transformers) (0.35.0)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/anaconda3/envs/AdvDB/lib/python3.13/site-packages (from transformers) (2.3.3)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/envs/AdvDB/lib/python3.13/site-packages (from transformers) (25.0)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/envs/AdvDB/lib/python3.13/site-packages (from transformers) (6.0.2)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/anaconda3/envs/AdvDB/lib/python3.13/site-packages (from transformers) (2025.9.18)\r\n",
      "Requirement already satisfied: requests in /opt/anaconda3/envs/AdvDB/lib/python3.13/site-packages (from transformers) (2.32.5)\r\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /opt/anaconda3/envs/AdvDB/lib/python3.13/site-packages (from transformers) (0.22.1)\r\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/anaconda3/envs/AdvDB/lib/python3.13/site-packages (from transformers) (0.6.2)\r\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/anaconda3/envs/AdvDB/lib/python3.13/site-packages (from transformers) (4.67.1)\r\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/anaconda3/envs/AdvDB/lib/python3.13/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.9.0)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/anaconda3/envs/AdvDB/lib/python3.13/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\r\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /opt/anaconda3/envs/AdvDB/lib/python3.13/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.10)\r\n",
      "Requirement already satisfied: torch>=1.11.0 in /opt/anaconda3/envs/AdvDB/lib/python3.13/site-packages (from sentence-transformers) (2.8.0)\r\n",
      "Requirement already satisfied: scikit-learn in /opt/anaconda3/envs/AdvDB/lib/python3.13/site-packages (from sentence-transformers) (1.7.2)\r\n",
      "Requirement already satisfied: scipy in /opt/anaconda3/envs/AdvDB/lib/python3.13/site-packages (from sentence-transformers) (1.16.2)\r\n",
      "Requirement already satisfied: Pillow in /opt/anaconda3/envs/AdvDB/lib/python3.13/site-packages (from sentence-transformers) (11.3.0)\r\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/envs/AdvDB/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers) (80.9.0)\r\n",
      "Requirement already satisfied: sympy>=1.13.3 in /opt/anaconda3/envs/AdvDB/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\r\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/envs/AdvDB/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers) (3.5)\r\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/envs/AdvDB/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/envs/AdvDB/lib/python3.13/site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/envs/AdvDB/lib/python3.13/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\r\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/anaconda3/envs/AdvDB/lib/python3.13/site-packages (from requests->transformers) (3.4.3)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/envs/AdvDB/lib/python3.13/site-packages (from requests->transformers) (3.7)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/envs/AdvDB/lib/python3.13/site-packages (from requests->transformers) (2.5.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/envs/AdvDB/lib/python3.13/site-packages (from requests->transformers) (2025.8.3)\r\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/anaconda3/envs/AdvDB/lib/python3.13/site-packages (from scikit-learn->sentence-transformers) (1.5.2)\r\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/anaconda3/envs/AdvDB/lib/python3.13/site-packages (from scikit-learn->sentence-transformers) (3.6.0)\r\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We can generate embeddings using HuggingFace's `sentence-transformers`. All it needs is to specify the model name and a list of sentences.\n",
   "id": "f3ea62a45754f2f9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-20T13:14:05.844871Z",
     "start_time": "2025-09-20T13:13:59.748880Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "sentences = [\"Call me Ishmael\", \"Some years ago—never mind how long precisely—having little or no money in my purse, and nothing particular to interest me on shore, I thought I would sail about a little and see the watery part of the world.\"]\n",
    "embeddings = model.encode(sentences)\n",
    "\n",
    "for sentence, embedding in zip(sentences, embeddings):\n",
    "    print(f\"Sentence: {sentence}\")\n",
    "    print(f\"Embedding: {embedding[:5]}...\")"
   ],
   "id": "52dfd2beea15baa",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: Call me Ishmael\n",
      "Embedding: [-0.0425336   0.03945521  0.05039315  0.00251705 -0.04552436]...\n",
      "Sentence: Some years ago—never mind how long precisely—having little or no money in my purse, and nothing particular to interest me on shore, I thought I would sail about a little and see the watery part of the world.\n",
      "Embedding: [0.07079883 0.05998563 0.05050527 0.06264909 0.08035159]...\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "If you check the embedding length above, it will be 384. This is the dimensionality of the embeddings.\n",
   "id": "1d7ea653f1f3503f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-20T13:14:05.887698Z",
     "start_time": "2025-09-20T13:14:05.885601Z"
    }
   },
   "cell_type": "code",
   "source": "print(len(embeddings[0]))",
   "id": "9ca6c92a60c85686",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "384\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### OpenAI\n",
    "\n",
    "OpenAI provides an API to generate embeddings using their advanced models. You can use the `openai` Python package to interact with the API.\n",
    "\n",
    "First, install the OpenAI package:"
   ],
   "id": "de4d7e9851cd06db"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-20T14:27:40.657813Z",
     "start_time": "2025-09-20T14:27:39.893778Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install openai",
   "id": "f8bc18b4d7e801e4",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /opt/anaconda3/envs/AdvDB/lib/python3.13/site-packages (1.108.1)\r\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/anaconda3/envs/AdvDB/lib/python3.13/site-packages (from openai) (4.7.0)\r\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/anaconda3/envs/AdvDB/lib/python3.13/site-packages (from openai) (1.9.0)\r\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/anaconda3/envs/AdvDB/lib/python3.13/site-packages (from openai) (0.28.1)\r\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /opt/anaconda3/envs/AdvDB/lib/python3.13/site-packages (from openai) (0.11.0)\r\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /opt/anaconda3/envs/AdvDB/lib/python3.13/site-packages (from openai) (2.11.7)\r\n",
      "Requirement already satisfied: sniffio in /opt/anaconda3/envs/AdvDB/lib/python3.13/site-packages (from openai) (1.3.0)\r\n",
      "Requirement already satisfied: tqdm>4 in /opt/anaconda3/envs/AdvDB/lib/python3.13/site-packages (from openai) (4.67.1)\r\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /opt/anaconda3/envs/AdvDB/lib/python3.13/site-packages (from openai) (4.15.0)\r\n",
      "Requirement already satisfied: idna>=2.8 in /opt/anaconda3/envs/AdvDB/lib/python3.13/site-packages (from anyio<5,>=3.5.0->openai) (3.7)\r\n",
      "Requirement already satisfied: certifi in /opt/anaconda3/envs/AdvDB/lib/python3.13/site-packages (from httpx<1,>=0.23.0->openai) (2025.8.3)\r\n",
      "Requirement already satisfied: httpcore==1.* in /opt/anaconda3/envs/AdvDB/lib/python3.13/site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\r\n",
      "Requirement already satisfied: h11>=0.16 in /opt/anaconda3/envs/AdvDB/lib/python3.13/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\r\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/anaconda3/envs/AdvDB/lib/python3.13/site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /opt/anaconda3/envs/AdvDB/lib/python3.13/site-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\r\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /opt/anaconda3/envs/AdvDB/lib/python3.13/site-packages (from pydantic<3,>=1.9.0->openai) (0.4.0)\r\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "OpenAPI has much higher-dimenstionality (better precision/quality) embedding models, like:\n",
    "\n",
    "- `text-embedding-3-small`\n",
    "- `text-embedding-3-large`\n",
    "- `text-embedding-3-base`\n",
    "- `text-embedding-3-mix`\n",
    "- `text-embedding-3-fine-tuned`\n",
    "\n",
    "and so on.\n"
   ],
   "id": "cec999569d89407b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-20T13:21:23.676116Z",
     "start_time": "2025-09-20T13:21:21.837875Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key=\"sk-proj-zOY****EBEA\")\n",
    "\n",
    "response = client.embeddings.create(\n",
    "    model=\"text-embedding-3-small\",\n",
    "    input=sentences\n",
    ")\n",
    "\n",
    "embeddings = [item.embedding for item in response.data]\n",
    "\n",
    "for sentence, embedding in zip(sentences, embeddings):\n",
    "    print(f\"Sentence: {sentence}\")\n",
    "    print(f\"Embedding length: {len(embedding)}\")\n",
    "    print(f\"First 5 values: {embedding[:5]}\")\n",
    "    print(\"---\")"
   ],
   "id": "34b40a2258b58156",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: Call me Ishmael\n",
      "Embedding length: 1536\n",
      "First 5 values: [0.007819030433893204, 0.015133155509829521, -0.0009440690628252923, 0.032959140837192535, -0.043506067246198654]\n",
      "---\n",
      "Sentence: Some years ago—never mind how long precisely—having little or no money in my purse, and nothing particular to interest me on shore, I thought I would sail about a little and see the watery part of the world.\n",
      "Embedding length: 1536\n",
      "First 5 values: [0.0020605484023690224, -0.004665764514356852, -0.012547033838927746, 0.07706713676452637, -0.012763588689267635]\n",
      "---\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "As you can see, embedding resolution (1536) is much higher than the free models. If you use some better model, you can get even higher resolution:",
   "id": "e8d7f3c65f73a62f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-20T13:23:08.986405Z",
     "start_time": "2025-09-20T13:23:08.015260Z"
    }
   },
   "cell_type": "code",
   "source": [
    "response = client.embeddings.create(\n",
    "    model=\"text-embedding-3-large\",\n",
    "    input=sentences\n",
    ")\n",
    "\n",
    "embeddings = [item.embedding for item in response.data]\n",
    "\n",
    "for sentence, embedding in zip(sentences, embeddings):\n",
    "    print(f\"Sentence: {sentence}\")\n",
    "    print(f\"Embedding length: {len(embedding)}\")\n",
    "    print(f\"First 5 values: {embedding[:5]}\")\n",
    "    print(\"---\")"
   ],
   "id": "1fa56f264389effd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: Call me Ishmael\n",
      "Embedding length: 3072\n",
      "First 5 values: [0.0021298318170011044, -0.016946136951446533, -0.0015679803909733891, 0.011603247374296188, -0.02826412208378315]\n",
      "---\n",
      "Sentence: Some years ago—never mind how long precisely—having little or no money in my purse, and nothing particular to interest me on shore, I thought I would sail about a little and see the watery part of the world.\n",
      "Embedding length: 3072\n",
      "First 5 values: [0.010106501169502735, 0.029184548184275627, -0.003808274632319808, -0.045645251870155334, 0.010237754322588444]\n",
      "---\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "OpenAI's models are behind a paywall, but as you can see, they are much more accurate than HuggingFace's models and justify their price. But HuggingFace models will be fine for your basic tasks.\n",
    "\n",
    "## Similarity Search\n",
    "\n",
    "Now that we understand embeddings and how to generate them, let's explore how to use these vectors for similarity search—that is, finding which stored embeddings are most similar to a given query embedding.\n",
    "\n",
    "### Cosine Similarity\n",
    "\n",
    "**Cosine similarity** measures the cosine of the angle between two vectors. This means it considers their direction, not their magnitude—so it's _scale-invariant_. If two vectors point in the same direction, their cosine similarity is 1; if they're orthogonal, it's 0; if they're opposite, it's -1. This is particularly useful for comparing embeddings, since the scale of the vectors often doesn't matter—just their orientation in space.\n",
    "\n",
    "**Intuition:** Two sentences with similar meaning will have embeddings pointing in similar directions, even if their magnitudes differ.\n",
    "\n",
    "**Code Example:**\n",
    "\n",
    "```python\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "```python\n",
    "\n",
    "```"
   ],
   "id": "b0094df13b8c6d2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-23T18:12:25.008451Z",
     "start_time": "2025-09-23T18:12:24.999186Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "embedding_a = np.array([0.1, 0.2, 0.7, 0.5, 0.3])\n",
    "embedding_b = np.array([0.2, 0.1, 0.6, 0.4, 0.4])\n",
    "\n",
    "def cosine_similarity(a, b):\n",
    "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
    "\n",
    "sim = cosine_similarity(embedding_a, embedding_b)\n",
    "print(f\"Cosine similarity: {sim:.3f}\")\n"
   ],
   "id": "774055c1940083da",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity: 0.973\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### L2 Distance\n",
    "\n",
    "**$L_2$ distance** (also called _Euclidean distance_) measures the straight-line distance between two points in space. For embeddings, this means the absolute difference between the vectors, taking both direction and magnitude into account. Smaller $L_2$ distances mean the vectors are closer together.\n",
    "\n",
    "**Intuition:** If two embeddings are \"close together\" in the vector space, their $L_2$ (Euclidean) distance will be small, indicating high similarity.\n",
    "\n",
    "**Code Example:**"
   ],
   "id": "a7170ed375baeef3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-20T13:25:52.744444Z",
     "start_time": "2025-09-20T13:25:52.741282Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "embedding_a = np.array([0.1, 0.2, 0.7, 0.5, 0.3])\n",
    "embedding_b = np.array([0.2, 0.1, 0.6, 0.4, 0.4])\n",
    "\n",
    "def l2_distance(a, b):\n",
    "    return np.linalg.norm(a - b)\n",
    "\n",
    "dist = l2_distance(embedding_a, embedding_b)\n",
    "print(f\"L2 (Euclidean) distance: {dist:.3f}\")"
   ],
   "id": "dd1d57f56a7c1a66",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L2 (Euclidean) distance: 0.224\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Now lets put it into perspective by taking some random vectors and performing a Cosine similarity search.\n",
   "id": "50338fe405bbb880"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-23T18:13:17.073860Z",
     "start_time": "2025-09-23T18:13:02.135464Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random.seed(37)\n",
    "db = np.random.rand(1000000, 1024).astype('float32')\n",
    "query = np.random.rand(1024).astype('float32')\n",
    "\n",
    "cos_sims = cosine_similarity(db, query)\n",
    "best_idx = np.argmax(cos_sims)\n",
    "print(f\"Brute-force best match index: {best_idx}, similarity: {cos_sims[best_idx]:.3f}\")\n"
   ],
   "id": "9cbb6d9fd9aca9ff",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brute-force best match index: 195311, similarity: 0.001\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Great. It worked. But if you have a look at the execution time for the above cell (~15 sec), its quite slow for search. Imagine you have to make some transaction and a 15 sec delay is quite intolerable. And we have taken 1 million vectors with 1024-dimension so far. No prize for guessing how long it will take with, say 1536 or 3072 length vectors.\n",
    "\n",
    "And the reason is clear, it has to sieve through all the points/vectors for comparison ($O(N)$). And dataset of millions or billions of vectors aren't uncommon, which means we need some better solution.\n",
    "\n",
    "## Approximate-Nearest Neighbours (ANN)\n",
    "\n",
    "Vector databases use approximation algorithms, which use some greedy searches to reach the nearest neighbhours. Like:\n",
    "\n",
    "- HNSW\n",
    "\n",
    "### HNSW\n",
    "\n",
    "(To be continued)"
   ],
   "id": "9360f622430c5771"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
